{mainmatter}

# Our use case #

For better understanding we will implement a small use case in both impure and pure way. The following section will outline the specification.

# Service specification

First we need to specify the exact scope and API of our service. We'll design a service with a minimal API to keep things simple. It shall fulfil the following requirements.

The service shall provide HTTP API endpoints for:

1. the creation of a product data type identified by a unique id
2. adding translations for a product name by language code and unique id
3. returning the existing translations for a product
4. returning a list of all existing products with their translations

## Data model

We will keep the model very simple to avoid going overboard with the implementation.

1. A language code shall be defined by the ISO 639-1 (e.g. a two letter code).
2. A translation shall contain a language code and a product name (non-empty string).
3. A product shall contain a unique id (UUID version 4) and a list of translations.

## Database

The data will be stored in a relational database (RDBMS). Therefore we need to define the tables and relations within the database.

### The products table

The table `products` must contain only the unique id which is also the primary key.

### The names table

The table `names` must contain a column for the product id, one for the language code and one for the name. Its primary key is the combination of the product id and the language code. All columns must not be null. The relation to the products is realised by a foreign key constraint to the `products` table via the product id.

## HTTP API

The HTTP API shall provide the following endpoints on the given paths:

| Path              | HTTP method | Function                              |
|-------------------|-------------|---------------------------------------|
| `/products`       | POST        | Create a product.                     |
| `/products`       | GET         | Get all products and translations.    |
| `/product/{UUID}` | PUT         | Add translations.                     |
| `/product/{UUID}` | GET         | Get all translations for the product. |

The data shall be encoded in JSON using the following specification:

{caption: "JSON for a translation"}
```json
{
  "lang": "ISO-639-1 Code",
  "name": "A non empty string."
}
```

{caption: "JSON for a product"}
```json
{
  "id": "The-UUID-of-the-product",
  "names": [
    // A list of translations.
  ]
}
```

This should be enough to get us started.

# The state of the art #

Within the Scala ecosystem the Akka-HTTP library is a popular choice for implementing server side backends for HTTP APIs. Another quite popular option is the Play framework but using a full blown web framework to just provide a thin API is overkill in most cases. As most services need a database the Slick library is another popular choice which completes the picture.

However while all mentioned libraries are battle tested and proven they still have problems.

# Problems

In the domain of functional programming we want referential transparency which we will define in the following way:

I> An expression `e` is referential transparent if we can in any given program replace any occurances of `e` with the result of the evaluation of `e` without changing the behaviour of the program.

Building on that we need pure functions which are

1. only dependent on their input
2. have no side effects

This means in turn that our functions will be referential transparent.

**But**, the mentioned libraries are built upon the `Future` from Scala which uses eager evaluation and breaks referential transparency. Let's look at an example.

{caption: "Future example 1"}
```scala
import scala.concurrent.Future
import scala.concurrent.ExecutionContext.Implicits.global

for {
  _ <- Future { println("Hi there!") }
  _ <- Future { println("Hi there!") }
} yield ()
```

The code above will print the text `Hi there!` two times. But how about the following one?

{caption: "Future example 2"}
```scala
import scala.concurrent.Future
import scala.concurrent.ExecutionContext.Implicits.global

val printF = Future { println("Hi there!") }

for {
  _ <- printF
  _ <- printF
} yield ()
```

Instead of printing the text two times it will print it only once even when there is no usage of `printF` at all (try omitting the for comprehension). This means that `Future` breaks referential transparency!

Q> So `Future` makes it harder (sometimes impossible) to reason about our code and also raises the bar for testability. What can we do?

# Maybe there is another way #

If we want referential transparency, we must push the side effects to the boundaries of our system (program) which can be done by using lazy evaluation. Let's repeat the previous example in a different way.

{caption: "IO example 1"}
```scala
import cats.effect.IO
import cats.implicits._

val effect = for {
  _ <- IO(println("Hi there!"))
  _ <- IO(println("Hi there!"))
} yield ()
```

The above code will produce no output. Only if we evaluate the variable `effect` which is of type `IO[Unit]` will the output be generated (try `effect.unsafeRunSync` in the REPL). Also the second approach works like expected.

{caption: "IO example 2"}
```scala
import cats.effect.IO
import cats.implicits._

val printF = IO(println("Hi there!"))

val effect = for {
  _ <- printF
  _ <- printF
} yield ()
```

Q> What have we gained?

Suddenly we can much more easily reason about our code! And why is that? Well we don't have unexpected side effects caused by code running even when it doesn't need to. This is a sneak peak how pure code looks like. Now we only need to implement pure libraries for our use, or do we?

Luckily for us meanwhile there are several pure options available in the Scala ecosystem. We will stick to the cats family of libraries namely http4s and Doobie as replacements for Akka-HTTP and Slick. They build upon the Cats Effect library which is an implementation of an IO monad for Scala. Some other options exist but we'll stick to the one from Cats.

To be able to contrast both ways of implementing a service we will first implement it using Akka-HTTP and Slick and will then migrate to http4s and Doobie.

# Impure implementation

We'll be using the following libraries for the impure version of the service:

1. Akka (including Akka-HTTP and Akka-Streams)
2. Slick (as database layer)
3. Flyway for database migrations (or evolutions)
4. Circe for JSON codecs and akka-http-json as wrapper
5. Refined for using refined types
6. the PostgreSQL JDBC driver

I'll spare you the sbt setup as you can look that up in the code repository (e.g. the `impure` folder in the book repo).

## Models

First we'll implement our models which are simple and straightforward. At first we need a class to store our translations or better a single translation.

```scala
final case class Translation(lang: String, name: String)
```

Q> So what is wrong with that approach?

Technically it is okay but we have a bad feeling about it. Using `Option[String]` is of no use because both fields have to be set. But a `String` can always be `null` and contain a lot of unexpected stuff (literally anything).

I> This is the moment when refined types come to you rescue!

So let us define some refined types which we can use later on. At first we need a language code which obeys the restrictions of ISO-639-1 and we need a stronger definition for a product name. For the former we use a regular expression and for the latter we simply expect a string which is not empty.

{caption: "Refined types for models"}
```scala
type LanguageCode = String Refined MatchesRegex[W.`"^[a-z]{2}$"`.T]
type ProductName = String Refined NonEmpty
```

Now we can give our translation model another try.

{caption: "Translation model using refined types"}
```scala
final case class Translation(lang: LanguageCode, name: ProductName)
```

Much better and while we're at it we can also write the JSON codecs using the refined module of the Circe library. We put them into the companion object of the model.

```scala
object Translation {
  implicit val decode: Decoder[Translation] =
    Decoder.forProduct2("lang", "name")(Translation.apply)

  implicit val encode: Encoder[Translation] =
    Encoder.forProduct2("lang", "name")(t => (t.lang, t.name))
}
```

Now onwards to the product model. Because we already know of refined types we can use them from start here.

```scala
type ProductId = String Refined Uuid
final case class Product(id: ProductId, names: List[Translation])
```

Q> Now what is wrong about this?

If we look closely we realise that a `List` maybe empty. Which is valid for the list but not for our product because we need at least one entry. Luckily for us the cats library has us covered with the `NonEmptyList` data type. Including the JSON codecs this leads us to our final implementation.
Last but not least we really should be using the existing `UUID` data type instead of rolling our own refined string version - even when it is cool. ;-)

{caption: "Product model using refined types and NeL"}
```scala
type ProductId = java.util.UUID
final case class Product(id: ProductId, names: NonEmptyList[Translation])

object Product {
  implicit val decode: Decoder[Product] =
    Decoder.forProduct2("id", "names")(Product.apply)

  implicit val encode: Encoder[Product] =
    Encoder.forProduct2("id", "names")(p => (p.id, p.names))
}
```

We kept the type name `ProductId` by using a type alias. This is convenient but remember that a type alias does not add extra type safety (e.g. `type Foo = String` will be a `String`).
Now we have the models covered and can move on to the database layer.

## Database layer

The database layer should provide a programmatic access to the database but also should it manage changes in the database. The latter one is called migrations or evolutions. From the available options we chose Flyway as the tool to manage our database schema.

### Migrations

Flyway uses raw SQL scripts which have to be put into a certain location being `src/main/resources/db/migration` in our case. Also the files have to be named like `VXX__some_name.sql` (`XX` being a number) starting with `V1`. Please note that there are two underscores between the version prefix and the rest of the name! Because our database schema is very simply we're done quickly:

{caption: "Flyway migration for creating the database"}
```sql
CREATE TABLE "products" (
  "id" UUID NOT NULL,
  CONSTRAINT "products_pk" PRIMARY KEY ("id")
);

CREATE TABLE "names" (
  "product_id" UUID       NOT NULL,
  "lang_code"  VARCHAR(2) NOT NULL,
  "name"       TEXT       NOT NULL,
  CONSTRAINT "names_pk" 
    PRIMARY KEY ("product_id", "lang_code"),
  CONSTRAINT "names_product_id_fk" 
    FOREIGN KEY ("product_id") 
    REFERENCES "products" ("id") 
    ON DELETE CASCADE ON UPDATE CASCADE
);
```

In the code you'll see that we additionally set comments which are omitted from the code snippet above. This might be overkill here but it is a very handy feature to have and I advice you to use it for more complicated database schemas. Because the right comment (read *information*) in the right place might save a lot of time when trying to understand things.

Next we move on to the programmatic part which at first needs a configuration of our database connection. With Slick you have a multitude of options but we'll use the "Typesafe Config"[^1] approach.

{caption: "Database configuration in application.conf"}
```text
db {
  connectionPool = "HikariCP"
  dataSourceClass = "org.postgresql.ds.PGSimpleDataSource"
  properties {
    serverName = "localhost"
    portNumber = "5432"
    databaseName = "impure"
    user = "impure"
    password = "secret"
  }
  numThreads = 10
}
```

After we have this in place we can run the migrations via the API of Flyway. For this we have to load the configuration (we do it by creating an actor system), extract the needed information and create a JDBC url and use that with username and password to obtain a Flyway instance. On that one we simply call the method `migrate()` which will do the right thing. Basically it will check if the schema exists and decide to either create it, apply pending migrations or simply do nothing. The method will return the number of applied migrations.

{caption: "Apply database migrations via Flyway"}
```scala
val as: ActorSystem = ActorSystem()
val url = "jdbc:postgresql://" +
  as.settings.config.getString("db.properties.serverName") +
  ":" + as.settings.config.getString("db.properties.portNumber") +
  "/" + as.settings.config.getString("db.properties.databaseName")
val user           = as.settings.config.getString("db.properties.user")
val pass           = as.settings.config.getString("db.properties.password")
val flyway: Flyway = Flyway.configure().dataSource(url, user, pass).load()
val _              = flyway.migrate()
```

Let us continue to dive into the Slick table definitions.

### Slick tables

Slick offers several options for approaching the database. For our example we will be using the lifted embedding but if needed Slick also provides the ability to perform plain SQL queries.
For the lifted embedding we have to define out tables in a way Slick can understand. While this can be tricky under certain circumstances our simple model is straightforward to implement.

{caption: "Slick product table definition"}
```scala
final class Products(tag: Tag) extends Table[(UUID)](tag, "products") {
  def id = column[UUID]("id", O.PrimaryKey)

  def * = (id)
}
val productsTable = TableQuery[Products]
```

As you can see above we're using simple data types (not the refined ones) to have a more easy Slick implementation. However we can also use refined types for the price of using either the slick-refined library or writing custom column mappers.
Next we'll implement the table for the translations which will also need some constraints.

{caption: "Slick translations table definition"}
```scala
final class Names(tag: Tag) extends Table[(UUID, String, String)](tag, "names") {
  def productId = column[UUID]("product_id")
  def langCode  = column[String]("lang_code")
  def name      = column[String]("name")

  def pk = primaryKey("names_pk", (productId, langCode))
  def productFk =
    foreignKey("names_product_id_fk", productId, productsTable)(
      _.id,
      onDelete = ForeignKeyAction.Cascade,
      onUpdate = ForeignKeyAction.Cascade
    )

  def * = (productId, langCode, name)
}
val namesTable = TableQuery[Names]
```

As you can see the definition of constraints is also pretty simple. Now our repository needs some functions for a more convenient access to the data.

{caption: "Slick repository functions"}
```scala
def loadProduct(id: ProductId): Future[Seq[(UUID, String, String)]] = {
  val program = for {
    (p, ns) <- productsTable join namesTable on (_.id === _.productId)
  } yield (p.id, ns.langCode, ns.name)
  dbConfig.db.run(program.result)
}

def saveProduct(p: Product): Future[List[Int]] = {
  val cp      = productsTable += (p.id)
  val program = DBIO.sequence(cp :: saveTranslations(p).toList)
    .transactionally
  dbConfig.db.run(program)
}

def updateProduct(p: Product): Future[List[Int]] = {
  val program = DBIO.sequence(saveTranslations(p).toList).transactionally
  dbConfig.db.run(program)
}

protected def saveTranslations(p: Product): NonEmptyList[DBIO[Int]] = {
  val save = saveTranslation(p.id)(_)
  p.names.map(t => save(t))
}

protected def saveTranslation(id: ProductId)(t: Translation): DBIO[Int] =
  namesTable.insertOrUpdate((id, t.lang, t.name))
```

The last two functions are helpers to enable us to create a load queries which we can compose. They are used in the `saveProduct` and `updateProduct` functions to create a list of queries that are executed as bulk while the call to `transactionally` ensures that they will run within a transaction.
The `loadProduct` function simply returns a list of database rows from the needed join. Therefore we need a function which builds a `Product` type out of that.

{caption: "Helper function to create a Product"}
```scala
def fromDatabase(rows: Seq[(UUID, String, String)]): Option[Product] = {
  val po = for {
    (id, c, n) <- rows.headOption
    t          <- Translation.fromUnsafe(c)(n)
    p          <- Product(id = id, names = NonEmptyList.one(t)).some
  } yield p
  po.map(
    p =>
      rows.foldLeft(p) { (a, cols) =>
	val (id, c, n) = cols
	Translation.fromUnsafe(c)(n).fold(a)(t =>
	  a.copy(names = a.names :+ t)
	)
    }
  )
}
```

So far we should have everything in place to make use of our database. Now we need to wire it all together.

### Akka-HTTP routes

# Pure implementation

# What about tests?

## Testing the impure service

## Testing the pure service

# Adding benchmarks

# Comparison


[^1]: http://slick.lightbend.com/doc/3.3.1/database.html
